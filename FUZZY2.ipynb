{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtz/9CMWz+LSisP4s4voLo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/allansdefreitas/unsupervised-learning/blob/main/FUZZY2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZxO_3aCYJySm"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#import skfuzzy\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from numpy import savetxt\n",
        "from numpy import loadtxt\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "\n",
        "def preprocess_dataset(dataframe):\n",
        "    \n",
        "    #pre-processing of dataset\n",
        "    scaler = StandardScaler()\n",
        "    data = scaler.fit_transform(dataframe.values)\n",
        "    \n",
        "    return data\n",
        "\n",
        "\n",
        "def initialize_membership_matrix(n_samples, n_clusters):\n",
        "    \"\"\"\n",
        "    Initializes the membership matrix for Fuzzy C-Means.\n",
        "\n",
        "    Parameters:\n",
        "        n_samples (int): Number of data points.\n",
        "        n_clusters (int): Number of clusters.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Initial membership matrix.\n",
        "    \"\"\"\n",
        "    membership_matrix = np.random.rand(n_samples, n_clusters)\n",
        "    membership_matrix /= np.sum(membership_matrix, axis=1, keepdims=True)\n",
        "    return membership_matrix\n",
        "\n",
        "\n",
        "def update_membership_matrix(data, centroids, m, distance_metric):\n",
        "    \"\"\"\n",
        "    Updates the membership matrix for Fuzzy C-Means.\n",
        "\n",
        "    Parameters:\n",
        "        data (numpy.ndarray): Input data points.\n",
        "        centroids (numpy.ndarray): Current centroid positions.\n",
        "        m (float): Fuzziness parameter.\n",
        "        distance_metric (str): Distance metric to use ('cityblock' or 'euclidean').\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Updated membership matrix.\n",
        "    \"\"\"\n",
        "    n_samples, n_clusters = data.shape[0], centroids.shape[0]\n",
        "    membership_matrix = np.zeros((n_samples, n_clusters))\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        for j in range(n_clusters):\n",
        "            if distance_metric == 'cityblock':\n",
        "                dist = np.sum(np.abs(data[i] - centroids[j]))\n",
        "            elif distance_metric == 'euclidean':\n",
        "                dist = np.linalg.norm(data[i] - centroids[j])\n",
        "            else:\n",
        "                raise ValueError(\"Invalid distance metric.\")\n",
        "\n",
        "            membership_matrix[i, j] = 1 / np.sum((dist / np.abs(data[i] - centroids)) ** (2 / (m - 1)))\n",
        "\n",
        "    membership_matrix /= np.sum(membership_matrix, axis=1, keepdims=True)\n",
        "    return membership_matrix\n",
        "\n",
        "\n",
        "def update_centroids(data, membership_matrix, m):\n",
        "    \"\"\"\n",
        "    Updates the centroids for Fuzzy C-Means.\n",
        "\n",
        "    Parameters:\n",
        "        data (numpy.ndarray): Input data points.\n",
        "        membership_matrix (numpy.ndarray): Current membership matrix.\n",
        "        m (float): Fuzziness parameter.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Updated centroid positions.\n",
        "    \"\"\"\n",
        "    n_clusters, n_features = membership_matrix.shape[1], data.shape[1]\n",
        "    centroids = np.zeros((n_clusters, n_features))\n",
        "\n",
        "    for j in range(n_clusters):\n",
        "        membership_power = membership_matrix[:, j] ** m\n",
        "        centroids[j] = np.sum(membership_power.reshape(-1, 1) * data, axis=0) / np.sum(membership_power)\n",
        "\n",
        "    return centroids\n",
        "\n",
        "def fuzzy_cmeans(data, n_clusters, m, distance_metric='cityblock', max_iter=100, tolerance=1e-4):\n",
        "    \"\"\"\n",
        "    Fuzzy C-Means clustering algorithm.\n",
        "\n",
        "    Parameters:\n",
        "        data (numpy.ndarray): Input data points.\n",
        "        n_clusters (int): Number of clusters.\n",
        "        m (float): Fuzziness parameter (> 1).\n",
        "        distance_metric (str): Distance metric to use ('cityblock' or 'euclidean').\n",
        "        max_iter (int): Maximum number of iterations.\n",
        "        tolerance (float): Convergence tolerance.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Final centroid positions.\n",
        "        numpy.ndarray: Membership matrix.\n",
        "        int: Number of iterations performed.\n",
        "    \"\"\"\n",
        "    n_samples, n_features = data.shape\n",
        "    membership_matrix = initialize_membership_matrix(n_samples, n_clusters)\n",
        "    centroids = np.zeros((n_clusters, n_features))\n",
        "\n",
        "    for iteration in range(max_iter):\n",
        "        prev_centroids = centroids.copy()\n",
        "\n",
        "        centroids = update_centroids(data, membership_matrix, m)\n",
        "        membership_matrix = update_membership_matrix(data, centroids, m, distance_metric)\n",
        "\n",
        "        if np.linalg.norm(centroids - prev_centroids) < tolerance:\n",
        "            break\n",
        "\n",
        "    return centroids, membership_matrix, iteration+1\n",
        "\n",
        "\n",
        "def calculate_objective(data, centroids, membership_matrix, m, distance_metric):\n",
        "    \"\"\"\n",
        "    Calculates the objective function value for Fuzzy C-Means.\n",
        "\n",
        "    Parameters:\n",
        "        data (numpy.ndarray): Input data points.\n",
        "        centroids (numpy.ndarray): Current centroid positions.\n",
        "        membership_matrix (numpy.ndarray): Current membership matrix.\n",
        "        m (float): Fuzziness parameter.\n",
        "        distance_metric (str): Distance metric to use ('cityblock' or 'euclidean').\n",
        "\n",
        "    Returns:\n",
        "        float: Objective function value.\n",
        "    \"\"\"\n",
        "    objective = 0\n",
        "    n_samples, n_clusters = data.shape[0], centroids.shape[0]\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        for j in range(n_clusters):\n",
        "            if distance_metric == 'cityblock':\n",
        "                dist = np.sum(np.abs(data[i] - centroids[j]))\n",
        "            elif distance_metric == 'euclidean':\n",
        "                dist = np.linalg.norm(data[i] - centroids[j])\n",
        "            else:\n",
        "                raise ValueError(\"Invalid distance metric.\")\n",
        "\n",
        "            objective += (membership_matrix[i, j] ** m) * (dist ** 2)\n",
        "\n",
        "    return objective\n",
        "\n",
        "#Modified partition coefficient e partition entropy --------------################\n",
        "\n",
        "#close to 1 values are better\n",
        "def calculate_mpc(membership_matrix):\n",
        "    \"\"\"\n",
        "    Calculates the Modified Partition Coefficient (MPC) for Fuzzy C-Means clustering.\n",
        "\n",
        "    Parameters:\n",
        "        membership_matrix (numpy.ndarray): Membership matrix of shape (n_samples, n_clusters).\n",
        "\n",
        "    Returns:\n",
        "        float: Modified Partition Coefficient value.\n",
        "    \"\"\"\n",
        "    max_memberships = np.max(membership_matrix, axis=1)\n",
        "    sum_memberships = np.sum(membership_matrix, axis=1)\n",
        "\n",
        "    mpc = np.mean(max_memberships / sum_memberships)\n",
        "\n",
        "    return mpc\n",
        "\n",
        "#close to 0 values are better\n",
        "def calculate_partition_entropy(membership_matrix):\n",
        "    \"\"\"\n",
        "    Calculates the Partition Entropy for Fuzzy C-Means clustering.\n",
        "\n",
        "    Parameters:\n",
        "        membership_matrix (numpy.ndarray): Membership matrix of shape (n_samples, n_clusters).\n",
        "\n",
        "    Returns:\n",
        "        float: Partition Entropy value.\n",
        "    \"\"\"\n",
        "    n_samples, n_clusters = membership_matrix.shape\n",
        "    entropy = 0.0\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        for j in range(n_clusters):\n",
        "            if membership_matrix[i, j] > 0:\n",
        "                entropy -= membership_matrix[i, j] * np.log2(membership_matrix[i, j])\n",
        "\n",
        "    partition_entropy = entropy / n_samples\n",
        "\n",
        "    return partition_entropy\n",
        "\n",
        "\n",
        "\"\"\"## Em cada dataset execute o algoritmo FCM com a distância de City-Block 50 vezes para obter \n",
        "uma partição fuzzy em 7 grupos e selecione o melhor resultado segundo a função objetivo.\"\"\"\n",
        "def get_best_partition(data, n_clusters, m, distance_metric = 'cityblock', times_to_run=50):\n",
        "    \n",
        "    best_objective_value = 99999999999.9\n",
        "    best_results = 0\n",
        "    TIMES = times_to_run\n",
        "    \n",
        "    for i in range(TIMES):\n",
        "    \n",
        "      # Example usage\n",
        "      #print(\"FCM: \", i + 1)\n",
        "    \n",
        "      centroids, membership_matrix, iterations = fuzzy_cmeans(data, n_clusters, m, distance_metric)\n",
        "      objective_value = calculate_objective(data, centroids, membership_matrix, m, distance_metric)\n",
        "      \n",
        "      \n",
        "      if(objective_value < best_objective_value):\n",
        "        best_objective_value = objective_value\n",
        "        best_results = centroids, membership_matrix, iterations\n",
        "    \n",
        "        #print(\"Centroids:\")\n",
        "        #print(centroids)\n",
        "        #print(\"Membership matrix:\")\n",
        "        #print(membership_matrix)\n",
        "        print(\"Objective value:\", objective_value)\n",
        "        #print(\"Iterations:\", iterations, \"\\n\")\n",
        "    \n",
        "    return best_results\n",
        "\n",
        "def fuzzy_to_crisp_partition(membership_matrix):\n",
        "    \"\"\"\n",
        "    Converts a fuzzy partition into a crisp partition.\n",
        "\n",
        "    Parameters:\n",
        "        membership_matrix (numpy.ndarray): Membership matrix of shape (n_samples, n_clusters).\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Crisp partition of shape (n_samples,).\n",
        "    \"\"\"\n",
        "    crisp_partition = np.argmax(membership_matrix, axis=1)\n",
        "\n",
        "    return crisp_partition\n",
        "\n",
        "\n",
        "def calculate_adjusted_rand_index(clustering):\n",
        "    \"\"\"\n",
        "    Calculates the Adjusted Rand Index (ARI) for a single clustering.\n",
        "\n",
        "    Parameters:\n",
        "        clustering (list or array-like): Cluster labels for each data point.\n",
        "\n",
        "    Returns:\n",
        "        float: Adjusted Rand Index (ARI) value.\n",
        "    \"\"\"\n",
        "    # Assuming you have a ground truth or reference clustering available,\n",
        "    # replace `ground_truth_labels` with the actual labels representing the ground truth.\n",
        "    ground_truth_labels = [0, 1, 1, 0, 2, 2]\n",
        "\n",
        "    ari = adjusted_rand_score(ground_truth_labels, clustering)\n",
        "    return ari\n",
        "\n",
        "\n",
        "def calculate_ari(clustering_1, clustering_2):\n",
        "\n",
        "  # Example clusterings\n",
        "  #clustering1 = [0, 0, 1, 1, 2, 2]\n",
        "  #clustering2 = [1, 1, 0, 0, 2, 2]\n",
        "\n",
        "  # Calculate ARI\n",
        "  ari = adjusted_rand_score(clustering_1, clustering_2)\n",
        "\n",
        "  return ari\n",
        "\n",
        "\n",
        "def calculate_f_measuree(clustering_1, clustering_2):\n",
        "\n",
        "  # Example clusterings\n",
        "  #clustering1 = [0, 0, 1, 1, 2, 2]\n",
        "  #clustering2 = [1, 1, 0, 0, 2, 2]\n",
        "\n",
        "  # Calculate F-measure\n",
        "  f_measure = metrics.fowlkes_mallows_score(clustering_1, clustering_2)\n",
        "  return f_measure"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "I. Considere os dados \"Image Segmentation\" do site uci machine learning\n",
        "repository (https://archive.ics.uci.edu/ml/datasets/Image+Segmentation).\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "NUMBER_OF_DATASETS = 3\n",
        "\n",
        "PATH = 'https://raw.githubusercontent.com/allansdefreitas/unsupervised-learning/main/segmentation.data'\n",
        "PATH2 = 'https://raw.githubusercontent.com/allansdefreitas/unsupervised-learning/main/segmentation.test'\n",
        "\n",
        "dataset_original = pd.read_csv(PATH, sep=',')\n",
        "dataset_original2 = pd.read_csv(PATH2, sep=',')\n",
        "\n",
        "#concat datasets\n",
        "frames = [dataset_original, dataset_original2]\n",
        "dataset_original_indexes = pd.concat(frames)\n",
        "\n",
        "dataset_original = dataset_original_indexes.reset_index(drop=True)\n",
        "\n",
        "indexes = dataset_original_indexes.index\n",
        "\n",
        "#obter os labels a priori\n",
        "indexes = dataset_original_indexes.index\n",
        "indexes_label = []\n",
        "\n",
        "for i in indexes:\n",
        "    indexes_label.append(i)\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "labels_a_priori = le.fit_transform(indexes_label)\n",
        "\n",
        "\n",
        "\"\"\" Considere 3 datasets: \"\"\"\n",
        "#o primeiro considerando as variáveis 4 a 9 (shape) ----------\n",
        "\n",
        "dataset_1 = dataset_original.iloc[:,3:9]\n",
        "#pre-processing of dataset\n",
        "X_dataset_1 = preprocess_dataset(dataset_1)\n",
        "\n",
        "\n",
        "#o segundo considerando as variaveis 10 a 19 (rgb) ----------\n",
        "dataset_2 = dataset_original.iloc[:,9:19]\n",
        "#pre-processing of dataset\n",
        "X_dataset_2 = preprocess_dataset(dataset_2)\n",
        "\n",
        "#O terceiro considerando as variaveis 4 a 19 (shape + rgb) -------\n",
        "dataset_3 = dataset_original.iloc[:,3:19]\n",
        "#pre-processing of dataset\n",
        "X_dataset_3 = preprocess_dataset(dataset_3)\n",
        "\n",
        "\n",
        "\"\"\" Em cada dataset execute o algoritmo FCM com a distância de City-Block\n",
        "50 vezes para obter uma partição fuzzy em 7 grupos e selecione o melhor\n",
        "resultado segundo a função objetivo. \"\"\""
      ],
      "metadata": {
        "id": "pcojygaCKxhO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a740081e-94b4-4f47-debd-2f2cad849d67"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Em cada dataset execute o algoritmo FCM com a distância de City-Block\\n50 vezes para obter uma partição fuzzy em 7 grupos e selecione o melhor\\nresultado segundo a função objetivo. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_a_priori"
      ],
      "metadata": {
        "id": "mJVFQ9CPadZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = X_dataset_1\n",
        "n_clusters = 7\n",
        "m = 1.1\n",
        "distance_metric = 'cityblock'\n",
        "best_objective_value = 99999999999.9\n",
        "best_results = 0\n",
        "times = 1 #50\n",
        "\n",
        "\n",
        "datasets = [X_dataset_1, X_dataset_2, X_dataset_3]\n",
        "best_results = []\n",
        "\n",
        "\n",
        "for dataset_i in datasets:\n",
        " \n",
        "   centroids, U, iter = get_best_partition(dataset_i, n_clusters, m, distance_metric = 'cityblock', times_to_run=times)\n",
        "   best_results.append([centroids, U, iter])\n",
        "\n",
        "\n",
        "#Salvar melhores matrizes de grau de associação (U) como arquivos csv\n",
        "\n",
        "#save datasets to csv files\n",
        "for i in range(NUMBER_OF_DATASETS):\n",
        "  data = best_results[i][1] #i-th membership_matrix\n",
        "\n",
        "  # save i-th dataset to csv file\n",
        "  filename = 'dataset_'+ str(i + 1)\n",
        "  savetxt(filename + '.csv', data, delimiter=',')\n",
        "\n",
        "#load datasets from csv files\n",
        "membership_matrixes = []\n",
        "\n",
        "for i in range(NUMBER_OF_DATASETS):\n",
        "\n",
        "  # save i-th dataset to csv file\n",
        "  filename = 'dataset_'+ str(i + 1)\n",
        "  data = loadtxt(filename + '.csv', delimiter=',') #recover #i-th membership_matrix\n",
        "  membership_matrixes.append(data) "
      ],
      "metadata": {
        "id": "Wfy-459dGUdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Para cada dataset e partição fuzzy, calcule o Modified partition coefficient\n",
        "e o Partition entropy. (OK. verificar) Comente\"\"\"\n",
        "\n",
        "#Obtendo MPC e partition entropy para cada dataset\n",
        "\n",
        "mpc_and_partition_entropy = []\n",
        "\n",
        "for ith_mem_matrix in membership_matrixes:\n",
        "\n",
        "  mpc = calculate_mpc(ith_mem_matrix)\n",
        "  partition_entropy = calculate_partition_entropy(ith_mem_matrix)\n",
        "\n",
        "  mpc_and_partition_entropy.append( [mpc, partition_entropy] )"
      ],
      "metadata": {
        "id": "jzOnO3gyM7JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Para cada dataset e partição fuzzy, produza uma partição crisp em 7\n",
        "grupos e calcule o índice de Rand corrigido, e a F-measure (adaptada\n",
        "para agrupamento). Comente \"\"\"\n",
        "\n",
        "\n",
        "#obtendo partiçoes CRISP\n",
        "crisp_partitions = []\n",
        "for i in range(NUMBER_OF_DATASETS):\n",
        "\n",
        "  crisp = fuzzy_to_crisp_partition(membership_matrixes[i])\n",
        "  crisp_partitions.append(crisp)\n",
        "\n",
        "\n",
        "#Obtendo ARI\n"
      ],
      "metadata": {
        "id": "AwK0Et8zPnO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtendo ARI\n",
        "clustering = crisp_partitions[0]\n",
        "ari = calculate_adjusted_rand_index(clustering)\n",
        "print(\"Adjusted Rand Index:\", ari)"
      ],
      "metadata": {
        "id": "COysxp-GWIzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(crisp)\n",
        "\n",
        "#entender via video aula etc sobre a aplicação do indice de rand corrigido e f-measure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJWiss96Qoit",
        "outputId": "a626b005-8db6-4946-c018-06c059efbee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    }
  ]
}